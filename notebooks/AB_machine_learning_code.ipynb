{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A/B testing with Machine learning code.ipynb\n",
    "## A/B Testing with Machine Learning\n",
    "Machine Learning enables modelling of complex systems unlike the statistical inference approach.\n",
    "\n",
    "Feature significance is what tells whether the experiment had some impact and also the contribution of other features.\n",
    "\n",
    "## Data\n",
    "The BIO data for this project is a “Yes” and “No” response of online users to the following question:\n",
    "\n",
    "\n",
    "`Q: Do you know the brand SmartAd?`\n",
    "\n",
    "      Yes\n",
    "      No\n",
    "The data has the following columns:\n",
    "  - \"auction_id\": the unique id of the online user who has been presented the BIO.\n",
    "  - \"experiment\": which group the user belongs to - control or exposed.\n",
    "  - \"date\": the date in YYYY-MM-DD format\n",
    "  - \"hour\": the hour of the day in HH format.\n",
    "  - \"device_make\": the name of the type of device the user has e.g. Samsung\n",
    "  - \"platform_os\": the id of the OS the user has.\n",
    "  - \"browser\": the name of the browser the user uses to see the BIO questionnaire.\n",
    "  - \"yes\": 1 if the user chooses the “Yes” radio button for the BIO questionnaire.\n",
    "  - \"no\": 1 if the user chooses the “No” radio button for the BIO questionnaire.\n",
    "\"\"\"\n",
    "\n",
    "#imoprtant liberaries\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from scipy.stats import skew, norm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "#read an csv file\n",
    "df = pd.read_csv(r'C:\\Users\\Smegn\\Documents\\GitHub\\AdSmart\\AdSmartABdata.csv')\n",
    "df.head(10)\n",
    "\n",
    "#missing value check\n",
    "df.isna().any()\n",
    "\n",
    "#classify columns by datatype and make list\n",
    "#data type =object\n",
    "categorical = ['auction_id', 'experiment', 'date', 'device_make', 'browser']\n",
    "#data type ='int16', 'int32', 'int64', 'float16', 'float32', 'float64\n",
    "numerical = ['hour', 'platform_os', 'yes', 'no']\n",
    "\n",
    "features = categorical + numerical \n",
    "df1 = df[features]\n",
    "df1.head(3)\n",
    "\n",
    "#Since data is sample data and we do not know total poulation so we can use z-score\n",
    "#to detect and remove outliers\n",
    "# identify outliers with z-score it helps us to understand\n",
    "# data value is greater or smaller than mean and how far away it is from the mean.\n",
    "\n",
    "#col_outlier=df[['hour','platform_os','yes','no','experiment','browser','device_make']]\n",
    "#z_scores = stats.zscore(col_outlier)\n",
    "#find absolute value of each element\n",
    "#abs_z_scores = np. abs(z_scores)\n",
    "#filter rows with outlier and remove\n",
    "#filtered_entries = (abs_z_scores < 3). all(axis=1)\n",
    "#cleaned data\n",
    "#new_df = df[filtered_entries]\n",
    "#new_df\n",
    "#plt.hist(z_scores)\n",
    "def is_outlier(data,col):\n",
    "    z_scores = stats.zscore(data[col])\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    if (abs_z_scores < 3). all():\n",
    "        print('there is  outlier')\n",
    "    else:\n",
    "        print('there is no outlier')\n",
    "        \n",
    "is_outlier(df,col) \n",
    "\n",
    "# Find skewed numerical features\n",
    "#result showes us except hour data hass highly skewed features\n",
    "skew_features = df1[numerical].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "print(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\n",
    "skewness = pd.DataFrame({'Skew' :high_skew})\n",
    "skew_features\n",
    "\n",
    "\"\"\"\n",
    "#you can check distribution of skewed variables using the code below\n",
    "     f, ax = plt.subplots(figsize=(7, 6))\n",
    "     sb.distplot(df1['platform_os'], bins = 20, color = 'blue')\n",
    "     ax.set(ylabel=\"Frequency\")\n",
    "     ax.set(xlabel=\"platform_os\")\n",
    "     ax.set(title=\"platform_os distribution\")\n",
    "\n",
    "     f, ax = plt.subplots(figsize=(7, 6))\n",
    "     sns.distplot(df['yes'], bins = 20, color = 'Magenta')\n",
    "     ax.set(ylabel=\"Frequency\")\n",
    "     ax.set(xlabel=\"yes\")\n",
    "     ax.set(title=\"yes distribution\")\n",
    " \"\"\"\n",
    "# get the location of the 3 categorical columns\n",
    "features = df.copy()\n",
    "indices = []\n",
    "for col in ['browser', 'experiment', 'device_make']:\n",
    "    k = features.columns.get_loc(col)\n",
    "    indices.append(k)\n",
    "    \n",
    "indices\n",
    " \n",
    "# Encoding categorical variables using Label Encoder\n",
    "columns = indices\n",
    "for col in columns:\n",
    "    x = features.iloc[:, col].values\n",
    "    x = x.reshape(-1,1)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder = encoder.fit(x)\n",
    "    x = encoder.transform(x)\n",
    "    features.iloc[:, col] = x \n",
    "\n",
    "# features = pd.get_dummies(df)\n",
    "print(features.shape)\n",
    "features.head()\n",
    "\n",
    "# create the target variable from the yes/no cols then drop yes/no cols\n",
    "\n",
    "# the 1st in yes remain the same, the 1st in no become 2s, the entries with 0s in both cols remain as 0s.\n",
    "features['target'] = 0\n",
    "\n",
    "features = features[features.target != 0]\n",
    "features.loc[features['target'] ==2, 'target'] = 0\n",
    "print(features.shape)\n",
    "features.target.value_counts()\n",
    "\n",
    "features.head()\n",
    "#dependent variable is target\n",
    "# dependent and independent variables\n",
    "x = features.drop(['target'], axis = 1)\n",
    "y = features[['target']]\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and test sets. (0.8, 0.20) split.\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)\n",
    "print('x train', x_train.shape)\n",
    "print('y train', y_train.shape)\n",
    "print('x test', x_test.shape)\n",
    "print('y test', y_test.shape)\n",
    "'''\n",
    "Training data set: When you use the entire data set for training the model, what you have is just the training data set. \n",
    "You train the model using the entire data set and test the model performance on the random data set taken from the entire\n",
    " training sample data set\n",
    "Validation data set: When you split the data set into two splits where the one split is called a\n",
    " training data set and another split is called a validation data set. You train the model using the\n",
    " training data set and evaluate the model performance using the validation data set. Generally, the \n",
    " training and validation data set is split into an 80:20 ratio. Thus, 20% of the data is set aside for validation purposes.\n",
    " The ratio changes based on the size of the data. In case, the data size is very large, one also goes for a 90:10 data split\n",
    " ratio where the validation data set represents 10% of the data.\n",
    "Test data set: When you split the data set into three splits, what we get is the test data set. \n",
    "The three splits consist of training data set, validation data set and test data set.\n",
    " You train the model using the training data set and assess the model performance using the validation data set. \n",
    " You optimize the model performance using training and validation data set. Finally, you test the model generalization\n",
    " performance using the test data set. The test data set remains hidden during the model training and model performance \n",
    " evaluation stage. One can split the data into a 70:20:10 ratio. 10% of the data set can be set aside as test data for\n",
    " testing the model performance. \n",
    "'''\n",
    "##I am using 80/20 % test and I thionk I donot need validation.\n",
    "'''\n",
    "ogistic probability score function allows the user to obtain a predicted probability score of a given event using a \n",
    "logistic regression model. The logistic probability score works by specifying the dependent variable \n",
    "(binary target) and independent variables as input\n",
    "'''\n",
    "     ##linear regration model ###\n",
    "with mlflow start_run()\n",
    "myreg=LinearRegression()\n",
    "myreg.fit(x_train,x_test)\n",
    "myreg.score(x_train,x_test)\n",
    "\n",
    "# feature importance\n",
    "feat_imp_dict = dict(zip(x_train.columns, myreg.coef_[0]))\n",
    "feat_imp = pd.DataFrame.from_dict(feat_imp_dict, orient='index')\n",
    "feat_imp.rename(columns = {0:'FeatureImportance'}, inplace = True)\n",
    "feat_imp.sort_values(by=['FeatureImportance'], ascending=False)\n",
    "\n",
    "# feature weights for every class\n",
    "coef_0=myreg.coef_[0]\n",
    "coef_1=myreg.coef_[1]\n",
    "coef_2=myreg.coef_[2]\n",
    "print(coef_0)\n",
    "print(coef_1)\n",
    "print(coef_2)\n",
    "\n",
    "##XGB\n",
    "xgbr = xgb.XGBRegressor(verbosity=0) \n",
    "print(xgbr)\n",
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=None, subsample=1, verbosity=1)\n",
    "       \n",
    "xgbr.fit(xtrain, ytrain)\n",
    "#After training the model, we'll check the model training score.\n",
    "\n",
    "score = xgbr.score(x_train, y_train)  \n",
    "print(\"Training score: \", score)\n",
    "#We can also apply the cross-validation method to evaluate the training score.\n",
    "\n",
    "scores = cross_val_score(xgbr, x_train, y_train,cv=5)\n",
    "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
    "\n",
    "#can predict test data, then check the prediction accuracy. \n",
    "#Here, we'll use MSE and RMSE as accuracy metrics.\n",
    "\n",
    "ypred = xgbr.predict(x_test)_\n",
    "mse = mean_squared_error(ytest, y_pred)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "MSE: 3.35\n",
    "print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "\n",
    "#visualize the original and predicted test data in a plot to compare visually.\n",
    "\n",
    "x_ax = range(len(y_test))\n",
    "plt.plot(x_ax, y_test, label=\"original\")\n",
    "plt.plot(x_ax, y_pred, label=\"predicted\")\n",
    "plt.title(\" test and predicted data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##Decision Trees##\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "scores = cross_val_score(estimator = tree, X = x_train, y = y_train, cv = 5)\n",
    "print(scores)\n",
    "print(\"mean decision trees score : \", scores.mean())\n",
    "# feature importance\n",
    "feat_importance = tree.tree_.compute_feature_importances(normalize=False)\n",
    "feat_imp_dict = dict(zip(x_train.columns, tree.feature_importances_))\n",
    "feat_imp_1 = pd.DataFrame.from_dict(feat_imp_dict, orient='index')\n",
    "feat_imp_1.rename(columns = {0:'FeatureImportance'}, inplace = True)\n",
    "feat_imp_1.sort_values(by=['FeatureImportance'], ascending=False).head()\n",
    "#visualize\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.barplot(y = feat_imp_1.FeatureImportance, x = feat_imp_1.index)\n",
    "plt.title('Feature Importances in Decision Trees')\n",
    "plt.xticks(rotation = 45)\n",
    "# using Decision Tree to run predictions on x_test\n",
    "y_pred = tree.predict(x_test)\n",
    "a = pd.DataFrame(y_pred)\n",
    "a.columns = ['pred']\n",
    "a.pred.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
